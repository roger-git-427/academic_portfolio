
# TCA Challenge - Time Series

This repository contains the solution to the time series challenge for the **TCA** project. The architecture is organized into multiple modules to clearly separate backend logic, frontend interface, inference services, and deployment configuration.

## ðŸ“ Project Structure

```bash
/
â”œâ”€â”€ backend/             # API backend (FastAPI, PostgreSQL, business logic)
â”œâ”€â”€ frontend/            # Dashboard interface (Dash)
â”œâ”€â”€ inference_api/       # Inference service for the time series model
â”œâ”€â”€ kubernetes_config/   # Kubernetes deployment configuration files
â”œâ”€â”€ my-kedro-project/    # Data preprocessing and model training pipeline (Kedro)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
```

## ðŸ“¦ Backend 

Contains the backend server developed with FastAPI. Its main function is to expose the necessary endpoints for handling predictions and interacting with the database.  
This is the full version of the inference service.

Relevant internal structure:

```bash
backend/
â”œâ”€â”€ .venv/               # Virtual environment (not in the repo but required)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/            # Main configuration 
â”‚   â”œâ”€â”€ db/              # Database session and SQLAlchemy models
â”‚   â”œâ”€â”€ models/          # Pydantic models (table schemas)
â”‚   â”œâ”€â”€ services/        # Predictions, queries
â”‚   â”œâ”€â”€ utils/           # Helper functions
â”‚   â””â”€â”€ main.py          # FastAPI entry point
â”œâ”€â”€ Dockerfile           # Backend image
â”œâ”€â”€ .env                 # Environment variables (not in the repo for security reasons)
â””â”€â”€ pyproject.toml       # Python dependencies
```

ðŸ”§ How to start the backend in development

```bash
cd backend
uv venv
source .venv/bin/activate      # Linux/macOS
# .venv\Scripts\activate     # Windows PowerShell
uv sync
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000 --reload
```

## ðŸ’» frontend

Developed in Dash, this module displays the dashboard with results, allows data upload, and visualizes metrics interactively.

Relevant internal structure:

```bash
frontend/
â”œâ”€â”€ .venv/               # Virtual environment (not in the repo but required)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ assets/          # CSS, images, and static resources
â”‚   â”œâ”€â”€ components/      # Reusable Dash components
â”‚   â”œâ”€â”€ utils/           # Helper functions for loading and processing data
â”‚   â””â”€â”€ main.py          # Dash app entry point
â”œâ”€â”€ Dockerfile           # Frontend image
â”œâ”€â”€ .env                 # Environment variables (not in the repo for security reasons)
â””â”€â”€ pyproject.toml       # Python dependencies
```

ðŸ”§ How to start the frontend in development

```bash
cd frontend
uv venv
source .venv/bin/activate      # Linux/macOS
# .venv\Scripts\activate     # Windows PowerShell
uv sync
uv run python -m app.main
# By default, it runs at http://127.0.0.1:8050
```

## ðŸ” inference_api

Contains the scripts needed to expose the time series prediction model, process data, and serve predictions through a standalone endpoint.  
This is the initial version of the backend, focused on inference.

## âš™ï¸ kubernetes_config

Includes the YAML manifests to deploy services in a Kubernetes cluster.

## ðŸ“Š my-kedro-project

Contains the full Kedro pipeline for data preprocessing and model training, organized in nodes and pipelines. See the final version in `final-tca-pipeline-reto`.

## ðŸš€ Workflow

**Preprocessing and Training**

Run the Kedro pipeline (in `my-kedro-project/final-tca-pipeline-reto`) to generate models and artifacts.

**Main Backend**

Start the backend for the general API.

**Dashboard**

Start the frontend for interactive visualization.

**Deployment**

Apply the manifests from `kubernetes_config` after building Docker images using the Dockerfiles.

âœ… General Requirements

Python >= 3.11
